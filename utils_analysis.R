################################################
# Paper title:	Over half of the negative crop yield variability explained by anthropogenic indicators
# Authors:	Pekka Kinnunen*, Matias Heino, Vilma Sandstr√∂m, Maija Taka, Deepak K. Ray, Matti Kummu
##
# Code author: Pekka Kinnunen
# Helper functions for data analysis
#################################################

fit_model_par <- function(.df, .group_names, .target_name, .var_names,
                          .nfolds, .run_parallel = FALSE, .seeds = NULL,
                          .spacevar = "country",
                          .ncores = NULL, ...) {

  dots <- list(...)
  # start cluster
  if (.run_parallel) {
    doMC::registerDoMC(cores = .ncores)
  }


  # get spacevar ids for test sets in each holdridge/crop split of the data
  test_folds <- lapply(.df, function(df, n) {
    splits <- CAST::CreateSpacetimeFolds(x = df,
                                         spacevar = .spacevar,
                                         k = n)

    split_out <- lapply(splits$indexOut,
                        function(split) unique(df[split,.spacevar] %>% pull())



                        )

    return(split_out)

  }, n = .nfolds)

  # loop over different holdridge regions and crops
  result_list <-
    foreach(i = 1:length(.df),
            .packages = c("tidyverse","caret","xgboost", "CAST")) %dopar% {
              df_holdridge <- .df[[i]]

              data_folds <- test_folds[[i]]

              out_preds <- tibble()
              pred_perf <- tibble()

              parts_out <- list()
              varimps_out <- list()
              shap_out <- list()
              test_values <- list()
              models_out <- list()

              # names for the list
              name_out <- df_holdridge[1, .group_names] %>%
                paste(., collapse = "//")

              for (jj in 1:length( data_folds )) {

                # country numbers
                spacevar_id <-  data_folds[[jj]]

                # train and test data
                df_train <- df_holdridge %>%
                  filter( !(.data[[.spacevar]] %in% spacevar_id))

                df_test <- df_holdridge %>%
                  filter(.data[[.spacevar]] %in% spacevar_id)


                # create train/test set folds for train foldwhere all points are from certain country
                folds <- CAST::CreateSpacetimeFolds(x = df_train,
                                                    spacevar = .spacevar,
                                                    k = nfolds)
                # target data
                target <- df_train %>%
                  pull(all_of(.target_name))

                # fit model with k-fold cv
                controls <- trainControl(method = "cv",
                                         number = length(folds$index),
                                         index = folds$index,
                                         indexOut = folds$indexOut,
                                         #search = "random",
                                         allowParallel = F,
                                         seeds = .seeds)

                model_LLO <-  caret::train(x = df_train[, preds],
                                           y = target,
                                           method = "xgbTree",
                                           metric = "RMSE",
                                           #tuneLength = ntunes,
                                           trControl = controls
                                           )

                # predict with test set and append the results
                cntry_preds <- predict(model_LLO, df_test[, preds])

                outcomes <- df_test %>%
                  mutate( preds = cntry_preds,
                          fold_n = paste0("fold_", jj))

                # get best model set
                best_model <- get_best_result(model_LLO)

                # collect model specs and accuracy for this fold
                test_rsq <- postResample(cntry_preds, df_test %>%
                                           pull(all_of(.target_name))) %>%
                  as_tibble_row() %>%
                  mutate(fold_ids = list(spacevar_id),
                         name_drop = name_out,
                         model_params = list(best_model) )

                pred_perf <- bind_rows(pred_perf, test_rsq)

                out_preds <- bind_rows(out_preds, outcomes)

                # get partial dependecy plots for each variable and variable importances
                partials <- lapply(.var_names,
                                   function(x) {
                  pdp::partial(model_LLO, x ) %>%
                                       as_tibble()
                                     }) %>%
                  bind_rows() %>%
                  pivot_longer(cols = all_of(.var_names),
                               names_to = "indicator",
                               values_to = "value") %>%
                  drop_na()

                name_fold <- paste0(name_out, "//fold_", jj)
                parts_out[[name_fold]] <- partials
                varimps_out[[name_fold]] <- xgb.importance(model = model_LLO$finalModel) %>%
                  as_tibble()
                shap_out[[name_fold]] <- shap.values(xgb_model = model_LLO$finalModel,
                                                   X_train = df_test[,preds] %>% as.matrix())
                test_values [[name_fold]] <- df_test

                models_out[[name_fold]] <- model_LLO

              }

              pdps <- bind_rows(parts_out, .id = "name") %>%
                separate(name, into = c(.group_names,"fold_n" ), sep = "//")

              var_imps <- bind_rows(varimps_out, .id = "name") %>%
                separate(name, into = c(.group_names,"fold_n" ), sep = "//")

              # gather results for the foreach loop
              list_out <- list(prediction_perf = pred_perf %>%
                                 separate(name_drop,
                                          into = .group_names,
                                          sep = "//"),
                               outcome_preds = out_preds,
                               pdp_data = pdps,
                               importances = var_imps,
                               shap_values = shap_out,
                               test_vals = test_values,
                               models = models_out,
                               m = model_LLO)

              return(list_out)
            }

  return(result_list)
}


plot_raster_im <- function(s_in, pal, breaks, land_outline, plot_size, plot_name) {
  for (i in 1:nlayers(s_in)) {

    r <- s_in[[i]]

    rname <- names(r)

    fig_out <- tm_shape(r) +
      tm_raster(palette = pal , style = "fixed", breaks = breaks) +
      tm_style("white",
               legend.show =  F,
               bg.color = "NA",
               earth.boundary = T,
               n = 100,
               space.color = "white",
               panel.show = F,
               legend.is.portrait = F) +
      # add coastline
      tm_shape(land_outline,projection = "robin") +
      tm_borders(col="black", lwd = 0.5)+
      tm_layout(legend.bg.color = TRUE,
                legend.outside.position = "bottom",
                legend.outside = TRUE,
                frame = FALSE,
                frame.lwd = NA, panel.label.bg.color = NA,
                earth.boundary = T,
                earth.boundary.lwd = NA,
                earth.boundary.color = "white",
                panel.show = F)

    tmap_save(fig_out,
              filename=paste0(path_to_results, "/",plot_name,"_", rname, ".pdf"),
              height = as.numeric(plot_size) ,
              width = as.numeric(plot_size)*2 ,
              units = "in")

  }
}


xgb_reg <- function(data_in, decision_name, seed_in = NULL) {

  cvControl <- caret::trainControl(method = "cv",
                            number = 2,
                            #search ="random",
                            allowParallel=F
                            )
  #
  #
    # tune_grid <- expand.grid(
    #   nrounds = c(50,100,200),
    #   eta = c(0.1, 0.3),
    #   max_depth = c(2, 5, 10),
    #   gamma = 5,
    #   colsample_bytree = 1,
    #   min_child_weight = c(1,10,15),
    #   subsample = 1
    # )
   #

  preds <- data_in %>%
    select(-all_of(decision_name))

  decision <- data_in %>%
    pull(all_of(decision_name))


  mod_fit <- caret::train(x = preds,
                   y= decision,
                   method = "xgbTree",
                   metric = "RMSE",
                   objective = "reg:squarederror",
                   trControl=cvControl
                   #tuneGrid = tune_grid,
                   #tuneLength = 60
                   )

  return (mod_fit)

}


f_predict <- function(models, test_data, decision_name){
  reg_data <- test_data %>% select(-all_of(decision_name))

  preds <- predict(models, newdata=test_data)

  decision <- test_data %>%
    pull(all_of(decision_name))


  perf <- postResample(preds, decision) %>%
    enframe()

  return(perf)
}

get_best_result = function(caret_fit) {
  best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
  best_result = caret_fit$results[best, ]
  rownames(best_result) = NULL
  return(best_result)
}


testNull <- function(model, data_in, decision_name){
  test_dec <- data_in %>% pull(all_of(decision_name))

  preds <- predict(model,
                   newdata = data_in %>%
                     select(-all_of(decision_name)))

  return(postResample(preds, test_dec))

}




